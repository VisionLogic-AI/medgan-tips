{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"top\"></a>\n",
    "<br/>\n",
    "# Understanding how `medGAN` works (on the MIMIC-III dataset with binary values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: [Sylvain Combettes](https://github.com/sylvaincom). <br/>\n",
    "Last update: Aug 29, 2019. Created: Aug 12, 2019. <br/>\n",
    "My own medGAN repository (that is based on Edward Choi's work): [medgan](https://github.com/sylvaincom/medgan-tips). <br/>\n",
    "Edward Choi's original repository: [medgan](https://github.com/mp2893/medgan).\n",
    "\n",
    "The final goal of my project is to use `medGAN` on my own dataset (electronic health records). Hence, I first need to understand how the `medGAN` program works. In this notebook, I provide a few code cells and explanations to help better understand and run `medGAN`. Because there are some confidentiality issues with the MIMIC-III dataset, I cleared the output of the cells.\n",
    "\n",
    "Before reading this notebook, make sure that you have read my [medGAN repository](https://github.com/sylvaincom/medgan-tips)'s table of contents.\n",
    "\n",
    "We will use the MIMIC-III dataset and process it so that we only have binary values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Table of contents\n",
    "\n",
    "- [Loading the MIMIC-III dataset](#load-mimic)\n",
    "- [Using `process_mimic.py` and `medgan.py` to generate the fake realistic data](#run)\n",
    "- [How can one interpret the output of `medgan.py`?](#gen-samples)\n",
    "- [How can one interpret the output of `process_mimic.py`?](#input)\n",
    "- [Comparing the (fake) generated samples to the real-life original ones](#comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Loading the MIMIC-III dataset <a name=\"load-mimic\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `ADMISSIONS.csv` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adm = pd.read_csv(\"ADMISSIONS.csv\")\n",
    "print(df_adm.shape)\n",
    "df_adm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do we have a lot of missing values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def observe_missing_values(df):\n",
    "    # This function does not return any values.\n",
    "    \n",
    "    dico = {}\n",
    "    c_index = [] # index of columns of features with missing values\n",
    "    n,p = df.shape\n",
    "    features = list(df) # list of features\n",
    "    \n",
    "    # We compute the percentage of missing values for each column:\n",
    "    for f in features:\n",
    "        percentage = round(sum(df[f].isna())*100/n, 2) # percentage of missing values\n",
    "        if percentage>0:\n",
    "            dico[f] = [percentage]\n",
    "            c_index.append(df.columns.get_loc(f))\n",
    "    \n",
    "    if c_index == []:\n",
    "        return 'There are no missing values!'\n",
    "    \n",
    "    # We construct the DataFrame ordered by Approx. missing values (%):\n",
    "    df_mv = pd.DataFrame(data=dico) # mv for missing values\n",
    "    idx_rename = {df_mv.index.tolist()[0]:'Approx. missing values (%)'}\n",
    "    df_mv = df_mv.rename(index=idx_rename)\n",
    "    \n",
    "    # We print the features with a decreasing Approx. missing values (%) value:\n",
    "    n_f = min(p,10) # number of features we choose to print\n",
    "    df_mv_ordered = df_mv.sort_values(by=['Approx. missing values (%)'], axis=1, ascending=False)\n",
    "    print('The', n_f, 'features with the most missing values are:')\n",
    "    print(df_mv_ordered.iloc[0].head(n_f))\n",
    "    \n",
    "    # We plot the Approx. missing values (%) given the index of the feature:\n",
    "    plt.plot(c_index, df_mv.iloc[0], 'o')\n",
    "    plt.xlabel('Index of feature')\n",
    "    plt.ylabel('Approx. missing values (%)')\n",
    "    plt.title('Observing missing values')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observe_missing_values(df_adm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `DIAGNOSES_ICD.csv` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ICD = pd.read_csv('DIAGNOSES_ICD.csv')\n",
    "print(df_ICD.shape)\n",
    "df_ICD.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do we have a lot of missing values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observe_missing_values(df_ICD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check if our dataset is balanced. Does one `ICD9_CODE` appear distinctly more than others in proportion?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ICD['ICD9_CODE'].value_counts(normalize=True).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Using `process_mimic.py` and `medgan.py` to generate the fake realistic data <a name=\"run\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step is detailed in [A few additional tips on how to run Edward Choi's medGAN](https://github.com/sylvaincom/medgan/blob/master/tips-for-medgan.md).\n",
    "\n",
    "In short, in the Anaconda prompt, we run:\n",
    "```\n",
    "cd C:\\Users\\<username>\\Documents\\mimic_binary\n",
    "python process_mimic.py ADMISSIONS.csv DIAGNOSES_ICD.csv training-data \"binary\"\n",
    "mkdir generated\n",
    "python medgan.py training-data.matrix ./generated/samples --data_type=\"binary\"\n",
    "python medgan.py training-data.matrix gen-samples --model_file=./generated/samples-999 --generate_data=True --data_type=\"binary\"\n",
    "```\n",
    "Some default values are `n_epoch=1000`, `n_pretrain_epoch=100` and `batch_size=1000`. We choose `nSamples=10000` line 405 in `medgan.py`.\n",
    "The computing took more than 5 hours on my laptop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From now on, whenever we refer to \"input\" or \"output\", we refer to the input and output of `medgan.py` (unless specified otherwise). \"input\" is the original real-life dataset and \"output\" is the fake realistic generated dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# How can one interpret the output of `medgan.py`? <a name=\"gen-samples\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the `gen-samples.npy` file which is `medgan.py`'s output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = np.load('gen-samples.npy')\n",
    "df_output = pd.DataFrame(output)\n",
    "print(df_output.shape)\n",
    "df_output.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the output of `medgan.py` have missing values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observe_missing_values(df_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of `medgan.py` has no missing values!\n",
    "\n",
    "Some questions about this data frame:\n",
    "* What do the columns correspond to? They are not the ones of `ADMISSIONS.csv` nor `DIAGNOSIS_ICD.csv`.\n",
    "* What do the rows correspond to?\n",
    "* Why are the values not binary?\n",
    "\n",
    "We can find some answers in an issue opened in Edward Choi's GitHub: [How to interpret the samples?](https://github.com/mp2893/medgan/issues/3). In order to understand the output `gen-samples.npy` of `medgan.py`, we are going to go back to the input of `medgan.py`: the output of `process_mimic.py` which is `training-data.matrix`.\n",
    "\n",
    "Actually, in `gen-samples.npy`, as in the `training-data.matrix` file, each row corresponds to a single patient and each column corresponds to a specific ICD9 diagnosis code. We can use the `training-data.types` file created by `process_mimic.py` to map each column to a specific ICD9 diagnosis code. Read the beginning part of the source code of `process_mimic.py` for more information about these files:\n",
    "```python\n",
    "# Output files\n",
    "# <output file>.pids: cPickled Python list of unique Patient IDs. Used for intermediate processing\n",
    "# <output file>.matrix: Numpy float32 matrix. Each row corresponds to a patient. Each column corresponds to a ICD9 diagnosis code.\n",
    "# <output file>.types: cPickled Python dictionary that maps string diagnosis codes to integer diagnosis codes.\n",
    "```\n",
    "\n",
    "What is ICD-9? See [ICD-9](https://en.wikipedia.org/wiki/International_Statistical_Classification_of_Diseases_and_Related_Health_Problems#ICD-9) and [List of ICD-9 codes](https://en.wikipedia.org/wiki/List_of_ICD-9_codes)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to round the values ourselves:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output = df_output.round(0)\n",
    "print(df_output.shape)\n",
    "df_output.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed, in line 405 of `medgan.py`, we have chosen `nSamples=10000`. It is important to note thay once we have learned the estimated density of the real-life original samples, we can generate as many fake realistic samples as we want."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# How can one interpret the output of `process_mimic.py`? <a name=\"input\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding `training-data.types`\n",
    "\n",
    "_cPickled Python dictionary that maps string diagnosis codes to integer diagnosis codes._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_dict = pickle.load(open('training-data.types', 'rb'))\n",
    "print(type(map_dict))\n",
    "print('An excerpt is:', dict(list(map_dict.items())[0:5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, as its name suggests, `process_mimic.py` is really dependent on the MIMIC-III dataset. We probably will not use `process_mimic.py` on our own dataset and only run `medgan.py`. Out of `process_mimic.py`, we only need to understand how the output file `training-data.matrix` is constructed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding `training-data.pids`\n",
    "\n",
    "_cPickled Python list of unique Patient IDs. Used for intermediate processing_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_list = pickle.load(open('training-data.pids', 'rb'))\n",
    "print(type(id_list))\n",
    "print('An excerpt is:', id_list[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding `training-data.matrix`\n",
    "\n",
    "_Numpy float32 matrix. Each row corresponds to a patient. Each column corresponds to a ICD9 diagnosis code._\n",
    "\n",
    "`training-data.matrix` is an output of `process_mimic.py` and the input of `medgan.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_array = pickle.load(open('training-data.matrix', 'rb'))\n",
    "print(type(input_data_array))\n",
    "input_data_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_input = pd.DataFrame(input_data_array)\n",
    "print(df_input.shape)\n",
    "df_input.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we chose, the input data is binary. \n",
    "\n",
    "We can note that the input and the [output](#gen-samples) of `medgan.py` have the same number of columns and that the values are of the same type (binary). Thus, `gen-samples.npy` is a (fake) realistic generated dataset that is trying to look like the `training-data.matrix` file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does the input of `medgan.py` have missing values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observe_missing_values(df_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input of `medgan.py` has no missing values!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Comparing the (fake) generated samples to the real-life original ones  <a name=\"comparison\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we wish to compare the accuracy of the (fake) generated dataset considering the original one. As in Choi's paper, we use dimension-wise probability (because the variables are binary).\n",
    "\n",
    "Given that our data is binary, for each feature (dimension), we claim that `1` corresponds to success and `0` to failure. Hence the proportion of `1` obtained is the Bernoulli success probability _p_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability distribution of the input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_input, p_input = df_input.shape\n",
    "print(n_input, p_input)\n",
    "\n",
    "proba_input = [sum(df_input[f])/n_input for f in list(df_input)]\n",
    "\n",
    "plt.plot(proba_input, 'o')\n",
    "plt.xlabel('Index of feature')\n",
    "plt.ylabel('Bernoulli probability success')\n",
    "plt.title('For the real-life dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability distribution of the output data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_output, p_output = df_output.shape\n",
    "print(n_output, p_output)\n",
    "\n",
    "proba_output = [sum(df_output[f])/n_output for f in list(df_output)]\n",
    "\n",
    "plt.plot(proba_output, 'o')\n",
    "plt.xlabel('Index of feature')\n",
    "plt.ylabel('Bernoulli probability success')\n",
    "plt.title('For the (fake) generated dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison: dimension-wise probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = min(np.min(proba_input), np.min(proba_output))\n",
    "stop = max(np.max(proba_input), np.max(proba_output))\n",
    "p = df_input.shape[1]\n",
    "X = np.linspace(start, stop, num=p+1)\n",
    "\n",
    "plt.plot(proba_input, proba_output, 'ok', X, X, '-g');\n",
    "\n",
    "plt.legend(['Bernoulli success probability', 'ideal Bernoulli success probability'])\n",
    "plt.title('Dimension-wise probability performance of medGAN')\n",
    "plt.xlabel('For the real dataset')\n",
    "plt.ylabel('For the (fake) generated dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values of the $x$-axis and the $y$-axis are ordered.\n",
    "\n",
    "The diagonal green line indicates the ideal performance where the real and the (fake) realistic generated data show identical quality. Based on the previous graph, we can say that medGAN has a really good performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Back to [top](#top)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"top\"></a>\n",
    "<br/>\n",
    "# Using `medGAN` to try to perform data augmentation on the MIMIC-III dataset with binary values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: [Sylvain Combettes](https://github.com/sylvaincom). <br/>\n",
    "Last update: Aug 29, 2019. Created: Aug 29, 2019. <br/>\n",
    "My own medGAN repository (that is based on Edward Choi's work): [medgan](https://github.com/sylvaincom/medgan-tips). <br/>\n",
    "Edward Choi's original repository: [medgan](https://github.com/mp2893/medgan).\n",
    "\n",
    "Before reading this notebook, make sure that you have read my [medGAN repository](https://github.com/sylvaincom/medgan-tips)'s table of contents.\n",
    "\n",
    "> **Using `medGAN` to try to perform data augmentation** <br/> <br/>\n",
    "With `medGAN`, we want to generate (fake) realistic patient data, which can then enrich the initial training database.\n",
    "For example, my training dataset $A$ is not large enough (let it be 500 samples with 50 features) and we want to use `medGAN` to generate a new dataset $B$ of 1000 fake samples (with 50 features as well). By adding $B$ to $A$, we get a new training dataset $C$ that has 1500 patients. We can hope that $C$ helps algorithms (any one of them) make better predictions than $A$. <br/> <br/>\n",
    "I asked Edward Choi what he thought about using the generative model GANs for data augmentation. Trying to generate fake realistic patients with `medGAN` from a dataset of 500 samples with 250 variables seems suboptimal: there seems to be too many variables and not enough samples. There is no definite number as to how many variables we need to delete: it depends on the variance of each variable and the correlation between variables. For example, if there is a variable named \"gender\" and all 500 samples are from men (thus low variance), then it would be very easy for `medGAN` to replicate that variable (by putting men as gender for each generated sample).\n",
    "\n",
    "We will use the MIMIC-III dataset and process it so that we only have binary values.\n",
    "\n",
    "From now on, whenever we refer to \"input\" or \"output\", we refer to the input and output of medgan.py (unless specified otherwise). \"input\" is the original real-life dataset and \"output\" is the fake realistic generated dataset.\n",
    "\n",
    "Warning: the computing time is very long."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Table of contents\n",
    "\n",
    "- [Loading the data](#load)\n",
    "- [Predicting the column of index `10` (called `target`) with (only) the original real-life dataset](#pred1)\n",
    "- [Predicting the column of index `10` (called `target`) with (only) the (fake) generated dataset](#pred2)\n",
    "- [Predicting the column of index `10` (called `target`) with data augmentation](#pred3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import model_selection, neural_network, model_selection, preprocessing, neighbors, naive_bayes, linear_model\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegressionCV, LogisticRegression, RidgeCV, LassoCV\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Loading the data <a name=\"load\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the real-life original dataset\n",
    "\n",
    "We call the real-life original dataset by `df_input`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_array = pickle.load(open('training-data.matrix', 'rb'))\n",
    "df_input = pd.DataFrame(input_data_array)\n",
    "print('The shape of the input dataset is :', df_input.shape)\n",
    "df_input.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the (fake) generated dataset\n",
    "\n",
    "We call the (fake) generated dataset by `df_output`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = np.load('gen-samples.npy')\n",
    "df_output = pd.DataFrame(output).round(0)\n",
    "print('The shape of the output dataset is :', df_output.shape)\n",
    "df_output.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing the feature we are going to try to predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which feature are we going to try to predict? For example, we want one with not only zeros (si it is harder to predict it)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df_input.sum()/df_input.shape[0], 'o')\n",
    "plt.xlabel('Index of feature')\n",
    "plt.ylabel('Proportion of 1s')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 10\n",
    "print('Approx. proportion of 1s of', target, ':', round(df_input[target].sum()/df_input.shape[0], 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Predicting the column of index `10` (called `target`) with (only) the original real-life dataset <a name=\"pred1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_input\n",
    "X_dataset = df.loc[:, df.columns != target].values\n",
    "y_dataset = np.ravel(df.loc[:, df.columns == target].values)\n",
    "print(X_dataset.shape, y_dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmarking some models according to their score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def prediction_benchmark(X_dataset, y_dataset):\n",
    "    \n",
    "    print('The shape of X_dataset is :', X_dataset.shape)\n",
    "    print('The shape of y_dataset is :', y_dataset.shape)\n",
    "    \n",
    "    rows_name = [\"1-Nearest Neighbors\", \"5-Nearest Neighbors\", \"10-Nearest Neighbors\", \"Naive Bayes\",\n",
    "                 \"Ridge\", \"Lasso\", \"Logistic Regression\", \"Perceptron\", \"Multi-Layer Perceptron\"]\n",
    "    \n",
    "    columns_name = ['Approx. mean of scores', 'Approx. variance of scores']\n",
    "    \n",
    "    l = []\n",
    "    \n",
    "    model = neighbors.KNeighborsClassifier(n_neighbors=1)\n",
    "    scores = model_selection.cross_val_score(model, X_dataset, y_dataset, cv=5)\n",
    "    l.append([round(scores.mean(), 3), round(scores.std()*2, 3)])\n",
    "    \n",
    "    model = neighbors.KNeighborsClassifier(n_neighbors=5)\n",
    "    scores = model_selection.cross_val_score(model, X_dataset, y_dataset, cv=5)\n",
    "    l.append([round(scores.mean(), 3), round(scores.std(), 3)])\n",
    "    \n",
    "    model = neighbors.KNeighborsClassifier(n_neighbors=10)\n",
    "    scores = model_selection.cross_val_score(model, X_dataset, y_dataset, cv=5)\n",
    "    l.append([round(scores.mean(), 3), round(scores.std(), 3)])\n",
    "    \n",
    "    model = naive_bayes.GaussianNB()\n",
    "    scores = model_selection.cross_val_score(model, X_dataset, y_dataset, cv=5)\n",
    "    l.append([round(scores.mean(), 3), round(scores.std(), 3)])\n",
    "    \n",
    "    model = RidgeCV(alphas=[1e-3, 1e-2, 1e-1, 1])\n",
    "    scores = model_selection.cross_val_score(model, X_dataset, y_dataset, cv=5)\n",
    "    l.append([round(scores.mean(), 3), round(scores.std(), 3)])\n",
    "    \n",
    "    model = LassoCV(cv=5, random_state=0)\n",
    "    scores = model_selection.cross_val_score(model, X_dataset, y_dataset, cv=5)\n",
    "    l.append([round(scores.mean(), 3), round(scores.std(), 3)])\n",
    "    \n",
    "    model = linear_model.LogisticRegression()\n",
    "    scores = model_selection.cross_val_score(model, X_dataset, y_dataset, cv=5)\n",
    "    l.append([round(scores.mean(), 3), round(scores.std(), 3)])\n",
    "    \n",
    "    model = linear_model.Perceptron()\n",
    "    scores = model_selection.cross_val_score(model, X_dataset, y_dataset, cv=5)\n",
    "    l.append([round(scores.mean(), 3), round(scores.std(), 3)])\n",
    "    \n",
    "    model = neural_network.MLPClassifier(hidden_layer_sizes=(6,),max_iter=1000,solver='lbfgs',alpha=.01)\n",
    "    scores = model_selection.cross_val_score(model, X_dataset, y_dataset, cv=5)\n",
    "    l.append([round(scores.mean(), 3), round(scores.std(), 3)])\n",
    "    \n",
    "    out = pd.DataFrame(l, index = rows_name, columns = columns_name)\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_benchmark = prediction_benchmark(X_dataset, y_dataset)\n",
    "input_benchmark.sort_values(by=['Approx. mean of scores'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Predicting the column of index `10` (called `target`) with (only) the (fake) generated dataset <a name=\"pred2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_output\n",
    "X_dataset = df.loc[:, df.columns != target].values\n",
    "y_dataset = np.ravel(df.loc[:, df.columns == target].values)\n",
    "print(X_dataset.shape, y_dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmarking some models according to their score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_benchmark = prediction_benchmark(X_dataset, y_dataset)\n",
    "output_benchmark.sort_values(by=['Approx. mean of scores'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Predicting the column of index `10` (called `target`) with data augmentation <a name=\"pred3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the data\n",
    "\n",
    "We concatenate the real-life dataset `df_input` and the (fake) generated dataset `df_output` into `df_aug`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aug = df_input.append(df_output)\n",
    "print(df_aug.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_aug\n",
    "X_dataset = df.loc[:, df.columns != target].values\n",
    "y_dataset = np.ravel(df.loc[:, df.columns == target].values)\n",
    "print(X_dataset.shape, y_dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmarking some models according to their score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_benchmark = prediction_benchmark(X_dataset, y_dataset)\n",
    "aug_benchmark.sort_values(by=['Approx. mean of scores'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Back to [top](#top)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"top\"></a>\n",
    "<br/>\n",
    "# Understanding how `medGAN` works on the MIMIC-III dataset of shape `(1000, 100)` with binary values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: [Sylvain Combettes](https://github.com/sylvaincom). <br/>\n",
    "Last update: Sep 4, 2019. Creation: Aug 12, 2019. <br/>\n",
    "My own medGAN repository (that is based on Edward Choi's work): [medgan-tips](https://github.com/sylvaincom/medgan-tips). <br/>\n",
    "Edward Choi's original repository: [medgan](https://github.com/mp2893/medgan).\n",
    "\n",
    "The final goal of my project is to use `medGAN` on my own dataset (electronic health records). Hence, I first need to understand how the `medGAN` program works. In this notebook, I provide a few code cells and explanations to help better understand and run `medGAN`. Because there are some confidentiality issues with the MIMIC-III dataset, I cleared the output of the cells.\n",
    "\n",
    "Before reading this notebook, make sure that you have read my [medGAN repository](https://github.com/sylvaincom/medgan-tips)'s table of contents.\n",
    "\n",
    "We will use the MIMIC-III dataset and process it so that we only have binary values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Tables of Contents\n",
    "\n",
    "- [1) Using process_`mimic.py` and `medgan.py` to generate the fake realistic data](#run)\n",
    "- [2) How to interpret `gen-samples.npy`?](#gen-samples)\n",
    "- [3) Comparing the (fake) generated samples to the real-life original ones](#comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a name=\"run\"></a>\n",
    "# 1) Using `process_mimic.py` and `medgan.py` to generate the fake realistic data \n",
    "\n",
    "This step is detailed in [A few additional tips on how to run Edward Choi's medGAN\n",
    "](https://github.com/sylvaincom/medgan/blob/master/tips-for-medgan.md).\n",
    "\n",
    "In short, in the Anaconda prompt, we run:\n",
    "```\n",
    "cd C:\\Users\\<username>\\Documents\\mimic_binary_small\n",
    "python process_mimic.py ADMISSIONS.csv DIAGNOSES_ICD.csv training-data \"binary\"\n",
    "mkdir generated\n",
    "```\n",
    "\n",
    "From now on, whenever we refer to input or output, we refer to the input and output of `medgan.py` (unless specified otherwise).\n",
    "\n",
    "`process_mimic.py` outputs `training-data.matrix` that contains 46 520 samples and 1 071 features. Because we need data augmentation only when our dataset is small, we assume that we only have 1 000 samples. Because we only have 1 000 samples now, it is quite difficult to generate 1 071 features out of 1 000 samples, so we only keep the 101st features.\n",
    "\n",
    "We keep only the 1000st samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_data_array = pickle.load(open('training-data.matrix', 'rb')) # real-life dataset\n",
    "df_real = pd.DataFrame(real_data_array)\n",
    "print(df_real.shape)\n",
    "\n",
    "df_real_small = df_real.head(1000) # we only select the 1000st samples\n",
    "print(df_real_small.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We keep only the 100st features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = list(df_real_small.columns)[100:1071]\n",
    "df_real_small.drop(col, axis=1, inplace=True)\n",
    "print(df_real_small.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now export our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = pd.DataFrame.as_matrix(df_real_small)\n",
    "pickle.dump(matrix, open('training-data-small.matrix', 'wb'), -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check if it was saved correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_data_array_small = pickle.load(open('training-data-small.matrix', 'rb'))\n",
    "df_real_small = pd.DataFrame(real_data_array_small)\n",
    "print(df_real_small.shape)\n",
    "df_real_small.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Anaconda prompt, we run:\n",
    "```\n",
    "python medgan.py training-data-small.matrix ./generated/samples --data_type=\"binary\" --n_epoch=1000 --n_pretrain_epoch=100 --batch_size=100\n",
    "python medgan.py training-data-small.matrix gen-samples --model_file=./generated/samples-999 --generate_data=True --data_type=\"binary\"\n",
    "```\n",
    "Some default values are `n_epoch=1000`, `n_pretrain_epoch=100` and `batch_size=1000`. We choose `nSamples=1000` line 406 in `medgan.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a name=\"gen-samples\"></a>\n",
    "# 2) How to interpret `gen-samples.npy`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the `gen-samples.npy` file which is `medgan.py`'s output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fict = np.load('gen-samples.npy') # fictitious generated dataset\n",
    "df_fict = pd.DataFrame(fict)\n",
    "print(df_fict.shape)\n",
    "df_fict.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ouput of `medgan.py` has no missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to round the values ourselves:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fict = df_fict.round(0)\n",
    "df_fict.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We claim that we should delete the rows with missing values (if there are any):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fict = pd.DataFrame.dropna(df_fict)\n",
    "print(df_fict.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a name=\"comparison\"></a>\n",
    "# 3) Comparing the fictitious generated samples to the real-life original ones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we wish to compare the accuracy of the fictitious generated dataset considering the original one. As in Choi's paper, we use dimension-wise probability (because the variables are binary).\n",
    "\n",
    "Given that our data is binary, for each feature (dimension), we claim that `1` corresponds to success and `0` to failure. Hence the proportion of `1` obtained is the Bernoulli success probability _p_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1) Probability distribution of real-life data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_real = df_real_small\n",
    "n_real, p_real = df_real.shape\n",
    "print(n_real, p_real)\n",
    "\n",
    "proba_real = [sum(df_real[f])/n_real for f in list(df_real)]\n",
    "\n",
    "plt.plot(proba_real, 'o')\n",
    "plt.xlabel('Index of feature')\n",
    "plt.ylabel('Bernoulli probability success')\n",
    "plt.title('For the real-life dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2) Probability distribution of fictitious generated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fict, p_fict = df_fict.shape\n",
    "print(n_fict, p_fict)\n",
    "\n",
    "proba_fict = [sum(df_fict[f])/n_fict for f in list(df_fict)]\n",
    "\n",
    "plt.plot(proba_fict, 'o')\n",
    "plt.xlabel('Index of feature')\n",
    "plt.ylabel('Bernoulli probability success')\n",
    "plt.title('For the fictitious generated dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3) Comparison: dimension-wise probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xaxis = proba_real\n",
    "yaxis = proba_fict\n",
    "\n",
    "start = min(np.min(xaxis), np.min(yaxis))\n",
    "stop = max(np.max(xaxis), np.max(yaxis))\n",
    "p = len(xaxis)\n",
    "X = np.linspace(start, stop, num=p+1)\n",
    "\n",
    "plt.plot(xaxis, yaxis, 'ok', X, X, '-g');\n",
    "\n",
    "plt.legend(['Bernoulli success probability', 'ideal Bernoulli success probability'])\n",
    "plt.title('Dimension-wise probability performance of medGAN')\n",
    "plt.xlabel('For the real dataset')\n",
    "plt.ylabel('For the fictitious generated dataset')\n",
    "plt.savefig('accuracy_mimic_binary_small.png', dpi=120) # to save the image in high resolution\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values of the $x$-axis and the $y$-axis are ordered: we successively compare the Bernoulli success probability of both datasets for a given variable.\n",
    "\n",
    "For information, we have 100 features thus 100 scatter points. Note that once we have learned the distribution of our real-life original data, we can generate as many (fake) samples as we want, for example 1 000.\n",
    "\n",
    "The diagonal green line indicates the ideal performance where the real and the fictitious realistic generated data show identical quality. Based on the graph, as the dots are close to the diagonal green line, we can say that `medGAN` has a really good accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Back to [top](#top)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
